{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eec6164e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: eli5==0.13.0 in /opt/conda/lib/python3.10/site-packages (0.13.0)\n",
      "Requirement already satisfied: attrs>17.1.0 in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (23.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (1.11.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (1.2.2)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (0.20.1)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (0.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=3.0.0->eli5==0.13.0) (2.1.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20->eli5==0.13.0) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20->eli5==0.13.0) (3.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "fonts-nanum is already the newest version (20180306-3).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 56 not upgraded.\n",
      "Train data shape :  (1118822, 52) Test data shape :  (9272, 51)\n",
      "Bus data shape :  (12584, 6) Subway data shape :  (768, 5)\n"
     ]
    }
   ],
   "source": [
    "!pip install eli5==0.13.0\n",
    "\n",
    "# # 한글 폰트 사용을 위한 라이브러리입니다.\n",
    "!apt-get install -y fonts-nanum\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "fe = fm.FontEntry(\n",
    "    fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf', # ttf 파일이 저장되어 있는 경로\n",
    "    name='NanumBarunGothic')                        # 이 폰트의 원하는 이름 설정\n",
    "fm.fontManager.ttflist.insert(0, fe)              # Matplotlib에 폰트 추가\n",
    "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumBarunGothic'}) # 폰트 설정\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "import seaborn as sns\n",
    "\n",
    "# utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "# Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "import build_transit_features as btf\n",
    "import geocode_concat as gc\n",
    "import nearest_subway as ns\n",
    "import nearest_bus_station as nbs\n",
    "\n",
    "train_path = \"~/apt-price/data/train.csv\"\n",
    "test_path = \"~/apt-price/data/test.csv\"\n",
    "bus_path = \"~/apt-price/data/bus_feature.csv\"\n",
    "subway_path = \"~/apt-price/data/subway_feature.csv\"\n",
    "\n",
    "dt = pd.read_csv(train_path)\n",
    "dt_test = pd.read_csv(test_path)\n",
    "bus_df = pd.read_csv(bus_path)\n",
    "subway_df = pd.read_csv(subway_path)\n",
    "\n",
    "# 데이터 shape 확인\n",
    "print('Train data shape : ', dt.shape, 'Test data shape : ', dt_test.shape)\n",
    "print('Bus data shape : ', bus_df.shape, 'Subway data shape : ', subway_df.shape)\n",
    "\n",
    "# train과 test 구분을 위한 컬럼을 만들어주고 하나의 데이터로 합쳐줌\n",
    "dt['is_test'] = 0\n",
    "dt_test['is_test'] = 1\n",
    "concat = pd.concat([dt, dt_test]) \n",
    "concat['is_test'].value_counts()\n",
    "\n",
    "# 어려운 컬럼 이름 바꿔줌\n",
    "concat = concat.rename(columns={'전용면적(㎡)':'전용면적', '좌표X':'경도', '좌표Y':'위도'})\n",
    "\n",
    "# 집값과 전혀 상관 없을 것 같은 아래 변수들은 과감히 지워줌\n",
    "concat.drop(columns=[\"해제사유발생일\",\n",
    "                    \"등기신청일자\",\n",
    "                    \"거래유형\",\n",
    "                    \"중개사소재지\",\n",
    "                    \"k-전화번호\",\n",
    "                    \"k-팩스번호\",\n",
    "                    \"단지소개기존clob\",\n",
    "                    \"k-홈페이지\",\n",
    "                    \"k-등록일자\",\n",
    "                    \"k-수정일자\",\n",
    "                    \"고용보험관리번호\",\n",
    "                    \"단지승인일\",\n",
    "                    \"관리비 업로드\",\n",
    "                    \"단지신청일\",\n",
    "                    'k-사용검사일-사용승인일',\n",
    "                    '사용허가여부',\n",
    "                    '기타/의무/임대/임의=1/2/3/4',\n",
    "                    '청소비관리형태',\n",
    "                    '세대전기계약방법',\n",
    "                    'k-관리방식',\n",
    "                    'k-단지분류(아파트,주상복합등등)',\n",
    "                    'k-시행사',\n",
    "                    'k-복도유형',\n",
    "                    'k-세대타입(분양형태)'], inplace=True)\n",
    "\n",
    "# 본번, 부번 str 형태로 수정\n",
    "concat_select = concat\n",
    "concat['본번'] = concat['본번'].astype('str')\n",
    "concat['부번'] = concat['부번'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지오코딩으로 위도, 경도 채워주기\n",
    "# concat_select2 = gc.geocode_concat_and_save_fast(\n",
    "#     df=concat_select,           # or concat_select\n",
    "#     sigungu_col=\"시군구\",\n",
    "#     bunji_col=\"번지\",\n",
    "#     output_csv=\"concat_select2_with_geo.csv\",\n",
    "#     sleep_sec=0.10               # 조금 더 빠르게; 필요시 0.08~0.12 조절\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e32a096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 너무 오래 걸리므로 미리 만들어놓음\n",
    "new_concat_select_path = \"concat_select2_with_geo.csv\"\n",
    "\n",
    "concat_select = pd.read_csv(new_concat_select_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48109847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_select에서 기존에 있었던 경도, 위도 컬럼 삭제하고 새로운 위도 경도 컬럼 이름 변경\n",
    "concat_select.drop(columns=[\"경도\",\n",
    "                    \"위도\"], inplace=True)\n",
    "\n",
    "concat_select = concat_select.rename(columns={'geo_lat':'위도', 'geo_lon':'경도'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b9778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 지하철역 피처 추가\n",
    "# concat_select2 = ns.add_subway_features(\n",
    "#     concat_select, subway_df,\n",
    "#     lat_col=\"위도\", lon_col=\"경도\",\n",
    "#     sub_lat_col=\"위도\", sub_lon_col=\"경도\",\n",
    "#     sub_name_col=\"역사명\",\n",
    "#     out_csv=\"concat_select2_with_subway.csv\"\n",
    "# )\n",
    "# \n",
    "# # 너무 오래 걸리므로 미리 만들어놓음\n",
    "# concat_select2_with_subway_path = \"concat_select2_with_subway.csv\"\n",
    "\n",
    "# concat_select = pd.read_csv(concat_select2_with_subway_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fa1042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bus] tree built in 0.01s  (n=12584)\n",
      "[bus] query points: 1110565/1128094\n",
      "[bus] nearest query: 19.77s\n",
      "[bus] radius 200m: 7.23s\n",
      "[bus] radius 300m: 8.08s\n",
      "[bus] radius 500m: 9.76s\n",
      "[bus] radius 1000m: 14.65s\n",
      "[bus] saved 'concat_select2_with_bus.csv' in 15.69s\n",
      "[bus] total 75.57s\n"
     ]
    }
   ],
   "source": [
    "# # 버스정류장 피처 추가\n",
    "# concat_select2 = nbs.add_bus_features(\n",
    "#     concat_select2, bus_df,\n",
    "#     lat_col=\"위도\", lon_col=\"경도\",\n",
    "#     bus_lat_col=\"Y좌표\", bus_lon_col=\"X좌표\",\n",
    "#     bus_name_col=\"정류소명\",\n",
    "#     out_csv=\"concat_select2_with_bus.csv\",\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# 너무 오래 걸리므로 미리 만들어놓음\n",
    "concat_select2_with_bus_path = \"concat_select2_with_bus.csv\"\n",
    "\n",
    "concat_select = pd.read_csv(concat_select2_with_bus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "281e6ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연속형 변수: ['본번', '부번', '전용면적', '계약년월', '계약일', '층', '건축년도', 'k-전체동수', 'k-전체세대수', 'k-연면적', 'k-주거전용면적', 'k-관리비부과면적', 'k-전용면적별세대현황(60㎡이하)', 'k-전용면적별세대현황(60㎡~85㎡이하)', 'k-85㎡~135㎡이하', 'k-135㎡초과', '건축면적', '주차대수', 'target', 'is_test', '위도', '경도', 'subway_dist_m', 'subway_walk_min', 'subway_cnt_300m', 'subway_cnt_500m', 'subway_cnt_1000m', 'bus_dist_m', 'bus_walk_min', 'bus_cnt_200m', 'bus_cnt_300m', 'bus_cnt_500m', 'bus_cnt_1000m']\n",
      "범주형 변수: ['시군구', '번지', '아파트명', '도로명', 'k-난방방식', 'k-건설사(시공사)', '경비비관리형태', 'subway_nearest_name', 'bus_nearest_name']\n"
     ]
    }
   ],
   "source": [
    "# 연속형 변수와 범주형 변수 분리\n",
    "continuous_columns = []\n",
    "categorical_columns = []\n",
    "\n",
    "for column in concat_select.columns:\n",
    "    if pd.api.types.is_numeric_dtype(concat_select[column]):\n",
    "        continuous_columns.append(column)\n",
    "    else:\n",
    "        categorical_columns.append(column)\n",
    "\n",
    "print(\"연속형 변수:\", continuous_columns)\n",
    "print(\"범주형 변수:\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3097cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수는 null을 채워서 보간해줌\n",
    "concat_select[categorical_columns] = concat_select[categorical_columns].fillna('NULL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9237d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k-135㎡초과                  0.999708\n",
       "k-전체동수                    0.777601\n",
       "건축면적                      0.776778\n",
       "주차대수                      0.776777\n",
       "k-85㎡~135㎡이하              0.776682\n",
       "k-전용면적별세대현황(60㎡~85㎡이하)    0.776682\n",
       "k-전용면적별세대현황(60㎡이하)        0.776682\n",
       "k-주거전용면적                  0.776682\n",
       "k-전체세대수                   0.776642\n",
       "k-연면적                     0.776642\n",
       "k-관리비부과면적                 0.776642\n",
       "subway_dist_m             0.015539\n",
       "bus_dist_m                0.015539\n",
       "bus_walk_min              0.015539\n",
       "bus_cnt_200m              0.015539\n",
       "bus_cnt_300m              0.015539\n",
       "subway_cnt_1000m          0.015539\n",
       "bus_cnt_500m              0.015539\n",
       "subway_cnt_500m           0.015539\n",
       "subway_cnt_300m           0.015539\n",
       "subway_walk_min           0.015539\n",
       "bus_cnt_1000m             0.015539\n",
       "경도                        0.015539\n",
       "위도                        0.015539\n",
       "target                    0.008219\n",
       "부번                        0.000066\n",
       "본번                        0.000066\n",
       "is_test                   0.000000\n",
       "건축년도                      0.000000\n",
       "층                         0.000000\n",
       "계약일                       0.000000\n",
       "계약년월                      0.000000\n",
       "전용면적                      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 연속형 변수는 어떻게 보간할까...\n",
    "# 단지 키(시군구+도로명+아파트명+건축년도)를 만들고 같은 단지 내 관측들에서 median 값으로 채우자\n",
    "concat_select[\"complex_key\"] = (\n",
    "    concat_select[\"시군구\"].astype(str).str.strip() + \"|\" +\n",
    "    concat_select[\"번지\"].astype(str).str.strip() + \"|\" +\n",
    "    concat_select[\"아파트명\"].astype(str).str.strip() + \"|\" +\n",
    "    concat_select[\"건축년도\"].astype(str).str.strip()\n",
    ")\n",
    "\n",
    "concat_select[continuous_columns].isna().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bbf7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _fill_by_group_median(df, col, group_cols):\n",
    "    # group_cols 순서대로 내려가며 채우기\n",
    "    s = df[col]\n",
    "    for gcols in group_cols:\n",
    "        med = df.groupby(gcols)[col].transform(\"median\")\n",
    "        s = s.fillna(med)\n",
    "    return s\n",
    "\n",
    "group_levels = [\n",
    "    [\"complex_key\"],                # 같은 단지\n",
    "    [\"시군구\",\"아파트명\"],             # 같은 시군구의 같은 아파트명\n",
    "    [\"시군구\"],                      # 같은 시군구\n",
    "]\n",
    "\n",
    "for col in continuous_columns:\n",
    "    if col not in concat_select.columns: \n",
    "        continue\n",
    "    was_na = concat_select[col].isna()\n",
    "    concat_select[col] = _fill_by_group_median(concat_select, col, group_levels)\n",
    "    # 전역 중앙값으로 최종 백업\n",
    "    concat_select[col] = concat_select[col].fillna(concat_select[col].median())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5dcedd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "시군구                       0\n",
       "번지                        0\n",
       "본번                        0\n",
       "부번                        0\n",
       "아파트명                      0\n",
       "전용면적                      0\n",
       "계약년월                      0\n",
       "계약일                       0\n",
       "층                         0\n",
       "건축년도                      0\n",
       "도로명                       0\n",
       "k-난방방식                    0\n",
       "k-전체동수                    0\n",
       "k-전체세대수                   0\n",
       "k-건설사(시공사)                0\n",
       "k-연면적                     0\n",
       "k-주거전용면적                  0\n",
       "k-관리비부과면적                 0\n",
       "k-전용면적별세대현황(60㎡이하)        0\n",
       "k-전용면적별세대현황(60㎡~85㎡이하)    0\n",
       "k-85㎡~135㎡이하              0\n",
       "k-135㎡초과                  0\n",
       "경비비관리형태                   0\n",
       "건축면적                      0\n",
       "주차대수                      0\n",
       "target                    0\n",
       "is_test                   0\n",
       "위도                        0\n",
       "경도                        0\n",
       "subway_dist_m             0\n",
       "subway_walk_min           0\n",
       "subway_nearest_name       0\n",
       "subway_cnt_300m           0\n",
       "subway_cnt_500m           0\n",
       "subway_cnt_1000m          0\n",
       "bus_dist_m                0\n",
       "bus_walk_min              0\n",
       "bus_nearest_name          0\n",
       "bus_cnt_200m              0\n",
       "bus_cnt_300m              0\n",
       "bus_cnt_500m              0\n",
       "bus_cnt_1000m             0\n",
       "complex_key               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_select.isnull().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "087ba15c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128094, 47)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########한강과 맞닿은 구인지 추가###############\n",
    "\n",
    "# 시군구, 년월 등 분할할 수 있는 변수들은 세부사항 고려를 용이하게 하기 위해 모두 분할해 주겠습니다.\n",
    "concat_select['구'] = concat_select['시군구'].map(lambda x : x.split()[1])\n",
    "concat_select['동'] = concat_select['시군구'].map(lambda x : x.split()[2])\n",
    "del concat_select['시군구']\n",
    "\n",
    "concat_select['계약년'] = concat_select['계약년월'].astype('str').map(lambda x : x[:4])\n",
    "concat_select['계약월'] = concat_select['계약년월'].astype('str').map(lambda x : x[4:])\n",
    "del concat_select['계약년월']\n",
    "\n",
    "# - 서울의 집값은 강남, 강북 여부에 따라 차이가 많이 난다는 사실은 많이 알려진 사실입니다.\n",
    "# - 따라서 강남/강북의 여부에 따라 파생변수를 생성해주도록 하겠습니다.\n",
    "all = list(concat_select['구'].unique())\n",
    "gangnam = ['강서구', '영등포구', '동작구', '서초구', '강남구', '송파구', '강동구']\n",
    "gangbuk = [x for x in all if x not in gangnam]\n",
    "\n",
    "assert len(all) == len(gangnam) + len(gangbuk)       # 알맞게 분리되었는지 체크합니다.\n",
    "# 강남의 여부를 체크합니다.\n",
    "is_gangnam = []\n",
    "for x in concat_select['구'].tolist() :\n",
    "  if x in gangnam :\n",
    "    is_gangnam.append(1)\n",
    "  else :\n",
    "    is_gangnam.append(0)\n",
    "\n",
    "# 파생변수를 하나 만릅니다.\n",
    "concat_select['강남여부'] = is_gangnam\n",
    "concat_select.columns\n",
    "\n",
    "# - 또한 신축인지, 구축인지의 여부도 실거래가에 큰 영향을 줄 수 있습니다.\n",
    "# - 따라서 건축년도에 따라 파생변수를 제작해주도록 하겠습니다.\n",
    "\n",
    "# 건축년도 분포는 아래와 같습니다. 특히 2005년이 Q3에 해당합니다.\n",
    "# 2009년 이후에 지어진 건물은 10%정도 되는 것을 확인할 수 있습니다.\n",
    "concat_select['건축년도'].describe(percentiles = [0.1, 0.25, 0.5, 0.75, 0.8, 0.9])\n",
    "\n",
    "# 따라서 2009년 이후에 지어졌으면 비교적 신축이라고 판단하고, 신축 여부 변수를 제작해보도록 하겠습니다.\n",
    "concat_select['신축여부'] = concat_select['건축년도'].apply(lambda x: 1 if x >= 2009 else 0)\n",
    "concat_select.head(1)       # 최종 데이터셋은 아래와 같습니다.\n",
    "concat_select.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c06426c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1118822, 46) (9272, 46)\n",
      "연속형 변수: ['본번', '부번', '전용면적', '계약일', '층', '건축년도', 'k-전체동수', 'k-전체세대수', 'k-연면적', 'k-주거전용면적', 'k-관리비부과면적', 'k-전용면적별세대현황(60㎡이하)', 'k-전용면적별세대현황(60㎡~85㎡이하)', 'k-85㎡~135㎡이하', 'k-135㎡초과', '건축면적', '주차대수', 'target', '위도', '경도', 'subway_dist_m', 'subway_walk_min', 'subway_cnt_300m', 'subway_cnt_500m', 'subway_cnt_1000m', 'bus_dist_m', 'bus_walk_min', 'bus_cnt_200m', 'bus_cnt_300m', 'bus_cnt_500m', 'bus_cnt_1000m', '강남여부', '신축여부']\n",
      "범주형 변수: ['번지', '아파트명', '도로명', 'k-난방방식', 'k-건설사(시공사)', '경비비관리형태', 'subway_nearest_name', 'bus_nearest_name', 'complex_key', '구', '동', '계약년', '계약월']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:02<00:00,  4.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# 이제 다시 train과 test dataset을 분할해줍니다. 위에서 제작해 놓았던 is_test 칼럼을 이용합니다.\n",
    "dt_train = concat_select.query('is_test==0')\n",
    "dt_test = concat_select.query('is_test==1')\n",
    "\n",
    "# 이제 is_test 칼럼은 drop해줍니다.\n",
    "dt_train.drop(['is_test'], axis = 1, inplace=True)\n",
    "dt_test.drop(['is_test'], axis = 1, inplace=True)\n",
    "print(dt_train.shape, dt_test.shape)\n",
    "dt_test.head(1)\n",
    "# dt_test의 target은 일단 0으로 임의로 채워주도록 하겠습니다.\n",
    "dt_test['target'] = 0\n",
    "\n",
    "# 파생변수 제작으로 추가된 변수들이 존재하기에, 다시한번 연속형과 범주형 칼럼을 분리해주겠습니다.\n",
    "continuous_columns_v2 = []\n",
    "categorical_columns_v2 = []\n",
    "\n",
    "for column in dt_train.columns:\n",
    "    if pd.api.types.is_numeric_dtype(dt_train[column]):\n",
    "        continuous_columns_v2.append(column)\n",
    "    else:\n",
    "        categorical_columns_v2.append(column)\n",
    "\n",
    "print(\"연속형 변수:\", continuous_columns_v2)\n",
    "print(\"범주형 변수:\", categorical_columns_v2)\n",
    "# 아래에서 범주형 변수들을 대상으로 레이블인코딩을 진행해 주겠습니다.\n",
    "\n",
    "# 각 변수에 대한 LabelEncoder를 저장할 딕셔너리\n",
    "label_encoders = {}\n",
    "\n",
    "# Implement Label Encoding\n",
    "for col in tqdm( categorical_columns_v2 ):\n",
    "    lbl = LabelEncoder()\n",
    "\n",
    "    # Label-Encoding을 fit\n",
    "    lbl.fit( dt_train[col].astype(str) )\n",
    "    dt_train[col] = lbl.transform(dt_train[col].astype(str))\n",
    "    label_encoders[col] = lbl           # 나중에 후처리를 위해 레이블인코더를 저장해주겠습니다.\n",
    "\n",
    "    # Test 데이터에만 존재하는 새로 출현한 데이터를 신규 클래스로 추가해줍니다.\n",
    "    for label in np.unique(dt_test[col]):\n",
    "      if label not in lbl.classes_: # unseen label 데이터인 경우\n",
    "        lbl.classes_ = np.append(lbl.classes_, label) # 미처리 시 ValueError발생하니 주의하세요!\n",
    "\n",
    "    dt_test[col] = lbl.transform(dt_test[col].astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08ae5279",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dt_train.shape[1] == dt_test.shape[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c2e5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target과 독립변수들을 분리해줍니다.\n",
    "y_train = dt_train['target']\n",
    "X_train = dt_train.drop(['target'], axis=1)\n",
    "\n",
    "# Hold out split을 사용해 학습 데이터와 검증 데이터를 8:2 비율로 나누겠습니다.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44457cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def make_safe_columns(df: pd.DataFrame):\n",
    "    # 1) 특수문자 -> '_' 치환\n",
    "    safe = [re.sub(r'[^\\w]+', '_', str(c)).strip('_') for c in df.columns]\n",
    "    # 2) 빈 이름/중복 처리\n",
    "    seen = {}\n",
    "    new_cols = []\n",
    "    for s in safe:\n",
    "        if s == '':\n",
    "            s = 'col'\n",
    "        if s in seen:\n",
    "            seen[s] += 1\n",
    "            s = f\"{s}_{seen[s]}\"\n",
    "        else:\n",
    "            seen[s] = 0\n",
    "        new_cols.append(s)\n",
    "    mapping = dict(zip(df.columns, new_cols))\n",
    "    return df.rename(columns=mapping), mapping\n",
    "\n",
    "# 전처리 끝난 데이터프레임들에 적용\n",
    "X_train, map_tr = make_safe_columns(X_train)\n",
    "X_val   = X_val.rename(columns=map_tr)\n",
    "# (있다면) X_test도 동일 매핑 적용\n",
    "# X_test  = X_test.rename(columns=map_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1969844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 14361.1\n",
      "[200]\tvalid_0's rmse: 11078\n",
      "[300]\tvalid_0's rmse: 9798.11\n",
      "[400]\tvalid_0's rmse: 9100.87\n",
      "[500]\tvalid_0's rmse: 8641.53\n",
      "[600]\tvalid_0's rmse: 8292.62\n",
      "[700]\tvalid_0's rmse: 8019.92\n",
      "[800]\tvalid_0's rmse: 7808.98\n",
      "[900]\tvalid_0's rmse: 7624.74\n",
      "[1000]\tvalid_0's rmse: 7462.16\n",
      "[1100]\tvalid_0's rmse: 7332.48\n",
      "[1200]\tvalid_0's rmse: 7220.67\n",
      "[1300]\tvalid_0's rmse: 7120.62\n",
      "[1400]\tvalid_0's rmse: 7025.28\n",
      "[1500]\tvalid_0's rmse: 6945.02\n",
      "[1600]\tvalid_0's rmse: 6876.94\n",
      "[1700]\tvalid_0's rmse: 6815.64\n",
      "[1800]\tvalid_0's rmse: 6758.65\n",
      "[1900]\tvalid_0's rmse: 6707.43\n",
      "[2000]\tvalid_0's rmse: 6660.92\n",
      "[2100]\tvalid_0's rmse: 6613.21\n",
      "[2200]\tvalid_0's rmse: 6564.77\n",
      "[2300]\tvalid_0's rmse: 6524.77\n",
      "[2400]\tvalid_0's rmse: 6485.66\n",
      "[2500]\tvalid_0's rmse: 6452.36\n",
      "[2600]\tvalid_0's rmse: 6420.43\n",
      "[2700]\tvalid_0's rmse: 6394.89\n",
      "[2800]\tvalid_0's rmse: 6367.93\n",
      "[2900]\tvalid_0's rmse: 6342.63\n",
      "[3000]\tvalid_0's rmse: 6315.92\n",
      "[3100]\tvalid_0's rmse: 6288.78\n",
      "[3200]\tvalid_0's rmse: 6271.68\n",
      "[3300]\tvalid_0's rmse: 6252.04\n",
      "[3400]\tvalid_0's rmse: 6233.58\n",
      "[3500]\tvalid_0's rmse: 6215.19\n",
      "[3600]\tvalid_0's rmse: 6197.49\n",
      "[3700]\tvalid_0's rmse: 6183.34\n",
      "[3800]\tvalid_0's rmse: 6166.37\n",
      "[3900]\tvalid_0's rmse: 6151.4\n",
      "[4000]\tvalid_0's rmse: 6136.58\n",
      "[4100]\tvalid_0's rmse: 6125.38\n",
      "[4200]\tvalid_0's rmse: 6111.92\n",
      "[4300]\tvalid_0's rmse: 6100.07\n",
      "[4400]\tvalid_0's rmse: 6086.7\n",
      "[4500]\tvalid_0's rmse: 6075.17\n",
      "[4600]\tvalid_0's rmse: 6064.05\n",
      "[4700]\tvalid_0's rmse: 6054.1\n",
      "[4800]\tvalid_0's rmse: 6045.08\n",
      "[4900]\tvalid_0's rmse: 6036.22\n",
      "[5000]\tvalid_0's rmse: 6028.34\n",
      "[5100]\tvalid_0's rmse: 6019.44\n",
      "[5200]\tvalid_0's rmse: 6009.72\n",
      "[5300]\tvalid_0's rmse: 6001.61\n",
      "[5400]\tvalid_0's rmse: 5994.43\n",
      "[5500]\tvalid_0's rmse: 5987.41\n",
      "[5600]\tvalid_0's rmse: 5979.72\n",
      "[5700]\tvalid_0's rmse: 5972.28\n",
      "[5800]\tvalid_0's rmse: 5966.13\n",
      "[5900]\tvalid_0's rmse: 5957.88\n",
      "[6000]\tvalid_0's rmse: 5951.61\n",
      "[6100]\tvalid_0's rmse: 5944.62\n",
      "[6200]\tvalid_0's rmse: 5940.1\n",
      "[6300]\tvalid_0's rmse: 5933.49\n",
      "[6400]\tvalid_0's rmse: 5928.39\n",
      "[6500]\tvalid_0's rmse: 5921.04\n",
      "[6600]\tvalid_0's rmse: 5914.99\n",
      "[6700]\tvalid_0's rmse: 5910.62\n",
      "[6800]\tvalid_0's rmse: 5906.51\n",
      "[6900]\tvalid_0's rmse: 5900.78\n",
      "[7000]\tvalid_0's rmse: 5895.49\n",
      "[7100]\tvalid_0's rmse: 5893.19\n",
      "[7200]\tvalid_0's rmse: 5889.42\n",
      "[7300]\tvalid_0's rmse: 5884.48\n",
      "[7400]\tvalid_0's rmse: 5880.93\n",
      "[7500]\tvalid_0's rmse: 5877.86\n",
      "[7600]\tvalid_0's rmse: 5874.39\n",
      "[7700]\tvalid_0's rmse: 5870.6\n",
      "[7800]\tvalid_0's rmse: 5866.4\n",
      "[7900]\tvalid_0's rmse: 5862.27\n",
      "[8000]\tvalid_0's rmse: 5858.45\n",
      "[8100]\tvalid_0's rmse: 5854.64\n",
      "[8200]\tvalid_0's rmse: 5851.33\n",
      "[8300]\tvalid_0's rmse: 5846.53\n",
      "[8400]\tvalid_0's rmse: 5844.19\n",
      "[8500]\tvalid_0's rmse: 5839.31\n",
      "[8600]\tvalid_0's rmse: 5836.65\n",
      "[8700]\tvalid_0's rmse: 5835.2\n",
      "[8800]\tvalid_0's rmse: 5831.99\n",
      "[8900]\tvalid_0's rmse: 5826.16\n",
      "[9000]\tvalid_0's rmse: 5824.53\n",
      "[9100]\tvalid_0's rmse: 5820\n",
      "[9200]\tvalid_0's rmse: 5817.39\n",
      "[9300]\tvalid_0's rmse: 5814.85\n",
      "[9400]\tvalid_0's rmse: 5812.26\n",
      "[9500]\tvalid_0's rmse: 5809.38\n",
      "[9600]\tvalid_0's rmse: 5806.56\n",
      "[9700]\tvalid_0's rmse: 5804.02\n",
      "[9800]\tvalid_0's rmse: 5801.65\n",
      "[9900]\tvalid_0's rmse: 5799.26\n",
      "[10000]\tvalid_0's rmse: 5796.14\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's rmse: 5796.14\n",
      "Valid RMSE: 5796.144483\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "params = dict(\n",
    "    objective=\"regression\",\n",
    "    metric=\"rmse\",\n",
    "    boosting_type=\"gbdt\",\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    min_data_in_leaf=30,\n",
    "    feature_fraction=0.9,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    lambda_l2=1.0,\n",
    "    n_estimators=10000,\n",
    "    random_state=42,\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "model = lgb.LGBMRegressor(**params)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric=\"rmse\",\n",
    "    callbacks=[lgb.early_stopping(200), lgb.log_evaluation(100)],\n",
    ")\n",
    "\n",
    "pred_val = model.predict(X_val)\n",
    "rmse = mean_squared_error(y_val, pred_val, squared=False)\n",
    "print(f\"Valid RMSE: {rmse:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd26fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lightgbm_transportation_ver_model2.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ead5db64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 4 ms, total: 13.7 s\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = dt_test.drop(['target'], axis=1)\n",
    "\n",
    "# Test dataset에 대한 inference를 진행합니다.\n",
    "real_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "766d03ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([194089.04427545, 306794.50018477, 333678.54998202, ...,\n",
       "        82507.70103943,  65214.24694872,  67148.66692148])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67273592",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.DataFrame(real_test_pred.astype(int), columns=[\"target\"])\n",
    "preds_df.to_csv('../outputs/output10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fff3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
